# VoiceGuard â€“ Dockerized Inference Environment

## ğŸ“Œ Overview

This project implements a **Dockerized Machine Learning Inference API** using **FastAPI**.
The application exposes REST endpoints for **health checks** and **real-time predictions**, with the ML model loaded safely inside the container.

The goal of this task is to demonstrate the ability to **containerize an inference service** with **clear build and run instructions**, suitable for production and MLOps workflows.

---

## ğŸ› ï¸ Tech Stack

* **Python 3.10**
* **FastAPI**
* **Uvicorn**
* **Docker**
* **scikit-learn**
* **NumPy**
* **Joblib**

---

## ğŸ“‚ Project Structure

```
.
fastapi-docker/
â”‚â”€â”€ app/
â”‚ â””â”€â”€ main.py
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ Dockerfile
â”‚â”€â”€ README.md
```

---

## ğŸš€ API Endpoints

### Health Check

```
GET /health
```

**Response**

```json
{
  "status": "healthy"
}
```

---

### Prediction

```
POST /predict
```

**Request Body**

```json
{
  "features": [5.1, 3.5, 1.4, 0.2]
}
```

**Response**

```json
{
  "prediction": [0]
}
```

---

## ğŸ³ Docker Build & Run Instructions

### Build Docker Image

```bash
docker build -t fastapi-inference .
```

### Run Container

```bash
docker run -d -p 8000:80 fastapi-inference

Container listens on port 80

Application is accessible on port 8000 of the host
```
### Access the Application
```bash
Swagger UI
http://localhost:8000/docs
```
---

## ğŸ§ª Testing the Service

### Health Endpoint

```bash
curl http://localhost:8000/health
```

### Prediction Endpoint

```bash
curl -X POST http://localhost:8000/predict \
-H "Content-Type: application/json" \
-d '{"features":[5.1,3.5,1.4,0.2]}'
```

---

## âš™ï¸ Key Implementation Details

* The ML model is loaded **lazily** to prevent startup crashes
* Docker image uses a **lightweight Python base image**
* API is designed to be **deployment-ready** (Docker, CI/CD, Kubernetes)
* Health endpoint enables monitoring and orchestration readiness

---

## âœ… Task Status

âœ” **Task Completed Successfully**
âœ” Inference API containerized and tested
âœ” Clear build and run instructions provided

---

## ğŸ“ˆ Future Enhancements

* Kubernetes Deployment & Service
* CI/CD pipeline integration
* Model versioning
* Authentication and request validation

---

## ğŸ‘¤ Author

**Sakshith Reddy**
Dockerized Inference Environment â€“ VoiceGuard Task
